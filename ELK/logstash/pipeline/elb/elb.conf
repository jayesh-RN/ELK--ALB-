input {
  s3 {
    bucket => "si-global-elb-logs-demo"
    prefix => "SI_ELB/"
    region => "us-east-1" 
    sincedb_path => "/var/lib/logstash/sincedb.log" # Path to track files processed
    codec => "plain" # ELB logs are plain text
  }
}


filter{
  # Backup original message
  mutate {
    add_field => { "[@metadata][original_message]" => "%{message}" }
  }

  # ELB log parsing using ECS pattern
  grok {
    match => {
      "message" => "%{ELB_V1_HTTP_LOG}"
    }
    tag_on_failure => ["_grokparsefailure"]
    timeout_millis => 10000
  }

  # Timestamp parsing with error handling
  date {
    match => [ "timestamp", "ISO8601" ]
    tag_on_failure => ["_dateparsefailure"]
  }

  # Field validation and cleanup (handling missing or invalid fields)
  mutate {
    gsub => [
      "request", '"', "",
      "trace_id", '"', "",
      "user_agent", '"', ""
    ]
  }




  # for indexing ............
  ruby {
      code => '
        folder_path = event.get("[@metadata][s3][key]")
        if folder_path
          immediate_folder = folder_path.split("/")[0] rescue nil     
          #-----> we can use what index we want
          # Convert to lowercase and set default to "unknown" if empty
          event.set("immediate_folder", (immediate_folder || "unknown").downcase)
        else
          event.set("immediate_folder", "unknown")  # Default to "unknown" if null
        end
      '
    }



  # Safe field parsing with error handling using Ruby
  ruby {
    code => '
      begin
        # Validate numeric fields
        ["request_processing_time", "target_processing_time", "response_processing_time", 
         "target_status_code", "received_bytes", "sent_bytes"].each do |field|
          if event.get(field)
            event.set(field, event.get(field).to_f) rescue event.set(field, 0.0)
          end
        end

        # Validate string fields
        ["request", "user_agent", "domain_name"].each do |field|
          if event.get(field).nil?
            event.set(field, "UNKNOWN")
          end
        end
      rescue => e
        event.tag("_fieldvalidationerror")
        event.set("[@metadata][validation_error]", e.message)
      end
    '
  }

  # Error aggregation
  if "_grokparsefailure" in [tags] or "_dateparsefailure" in [tags] or "_fieldvalidationerror" in [tags] {
    mutate {
      add_field => {
          "error_details" => {
            "timestamp" => "%{@timestamp}"
            "original_message" => "%{[@metadata][original_message]}"
            "error_tags" => "%{tags}"
          }
      }
    }
  }
}



output {
  if "_grokparsefailure" in [tags] or "_dateparsefailure" in [tags] or "_fieldvalidationerror" in [tags] {
    # Route failed logs elasticsearch 
    elasticsearch {
      hosts => ["http://elasticsearch:9200"] 
      index => "elb-logs-failed-%{immediate_folder}-%{+YYYY.MM.dd}"  # Include only the immediate folder in the index nam
    }
  } else {
    # Route successful events to an index based on the immediate folder name
    elasticsearch {
      hosts => ["http://elasticsearch:9200"] 
      index => "elb-logs-%{immediate_folder}-%{+YYYY.MM.dd}"  # Include only the immediate folder in the index name
    }
  }
  stdout {
    codec => rubydebug
  }
}
